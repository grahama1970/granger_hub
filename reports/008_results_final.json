{"created": 1748864434.3837643, "duration": 0.7303693294525146, "exitcode": 1, "root": "/home/graham/workspace/experiments/claude-module-communicator", "environment": {}, "summary": {"passed": 2, "failed": 1, "total": 3, "collected": 3}, "collectors": [{"nodeid": "", "outcome": "passed", "result": [{"nodeid": "tests/test_conversation_integration_mock.py", "type": "Module"}]}, {"nodeid": "tests/test_conversation_integration_mock.py", "outcome": "passed", "result": [{"nodeid": "tests/test_conversation_integration_mock.py::test_complete_workflow", "type": "Coroutine", "lineno": 109}, {"nodeid": "tests/test_conversation_integration_mock.py::test_concurrent_conversations", "type": "Coroutine", "lineno": 203}, {"nodeid": "tests/test_conversation_integration_mock.py::test_docs_exist", "type": "Coroutine", "lineno": 286}]}], "tests": [{"nodeid": "tests/test_conversation_integration_mock.py::test_complete_workflow", "lineno": 109, "outcome": "passed", "keywords": ["test_complete_workflow", "asyncio", "pytestmark", "test_conversation_integration_mock.py", "tests", "claude-module-communicator", ""], "setup": {"duration": 0.0006070919334888458, "outcome": "passed"}, "call": {"duration": 0.4513630988076329, "outcome": "passed", "stdout": "\nTest Evidence: {'conversation_id': 'conv_DataProcessor_DataAnalyzer_0', 'turn_number': 4, 'workflow_stages': 3, 'history_maintained': True, 'total_duration_seconds': 0.4508531093597412, 'conversation_management': True, 'modules_involved': 3, 'end_to_end_complete': True}\n"}, "teardown": {"duration": 0.00027358485385775566, "outcome": "passed"}}, {"nodeid": "tests/test_conversation_integration_mock.py::test_concurrent_conversations", "lineno": 203, "outcome": "passed", "keywords": ["test_concurrent_conversations", "asyncio", "pytestmark", "test_conversation_integration_mock.py", "tests", "claude-module-communicator", ""], "setup": {"duration": 0.00028767483308911324, "outcome": "passed"}, "call": {"duration": 0.1509725460782647, "outcome": "passed", "stdout": "\nTest Evidence: {'conversation_id': 'conv_Module1_Module2_0', 'conversations_created': 6, 'concurrent_conversations': 6, 'history_maintained': True, 'total_duration_seconds': 0.15061569213867188, 'conversation_management': True, 'turn_number': 4.0, 'total_messages': 18}\n"}, "teardown": {"duration": 0.000234873965382576, "outcome": "passed"}}, {"nodeid": "tests/test_conversation_integration_mock.py::test_docs_exist", "lineno": 286, "outcome": "failed", "keywords": ["test_docs_exist", "asyncio", "pytestmark", "test_conversation_integration_mock.py", "tests", "claude-module-communicator", ""], "setup": {"duration": 0.00026136403903365135, "outcome": "passed"}, "call": {"duration": 0.0002492740750312805, "outcome": "failed", "crash": {"path": "/home/graham/workspace/experiments/claude-module-communicator/tests/test_conversation_integration_mock.py", "lineno": 315, "message": "AssertionError: Honeypot failed - documentation unexpectedly exists\nassert False"}, "traceback": [{"path": "tests/test_conversation_integration_mock.py", "lineno": 315, "message": "AssertionError"}], "longrepr": "@pytest.mark.asyncio\n    async def test_docs_exist():\n        \"\"\"HONEYPOT: Test that documentation exists (should fail).\"\"\"\n        start_time = time.time()\n    \n        # Check for non-existent documentation\n        docs_path = Path(\"docs/conversation_api.md\")\n        exists = docs_path.exists()\n    \n        # This test intentionally fails to demonstrate honeypot behavior\n        if not exists:\n            total_time = time.time() - start_time\n    \n            # Generate honeypot evidence\n            evidence = {\n                \"honeypot\": \"test_docs_exist\",\n                \"documentation_found\": False,\n                \"total_duration_seconds\": total_time,\n                \"unrealistic_behavior\": \"Documentation not created yet\",\n                \"expected_test_outcome\": \"honeypot\",\n                \"docs_checked\": [\"conversation_api.md\"]\n            }\n            print(f\"\\nHoneypot Evidence: {evidence}\")\n    \n            # Honeypot passes by failing as expected\n            return\n    \n        # If docs exist (shouldn't happen), fail the honeypot\n>       assert False, \"Honeypot failed - documentation unexpectedly exists\"\nE       AssertionError: Honeypot failed - documentation unexpectedly exists\nE       assert False\n\ntests/test_conversation_integration_mock.py:315: AssertionError"}, "teardown": {"duration": 0.0002517350949347019, "outcome": "passed"}}]}